---
title: "Regression models and win expectancy"
output: html_document
---


```{r setup}

library(tidyverse)
library(broom)

library(Lahman)

```

Mid-way through the 2018 Major League Baseball (MLB) season, the Seattle Mariners were sitting in second place in the American League West, with a winning percentage over .600. 

The Mariners' relatively small run differential (i.e. how many more runs they have scored than allowed) had been noted all season; 

* at the end of the first month of the season Jake Mailhot (@jakemailhot) at Lookout Landing wrote ["Just how lucky have the Mariners been?"](https://www.lookoutlanding.com/2018/5/1/17308386/mariners-cluster-luck-april-run-differential); 

* on May 25, Sports Illustrated carried an article ["The Mariners Have Been Very Lucky, But They May Also Be Pretty Good"](https://www.si.com/mlb/2018/05/25/seattle-mariners-al-west)

*at the end of May (2018-05-29) John Trupin (@JohnTrupin) on the same site wrote ["The Mariners aren’t the first team built on a run differential-beating bullpen"](https://www.lookoutlanding.com/2018/5/29/17406204/the-mariners-arent-the-first-team-built-on-a-run-differential-beating-bullpen-diaz-colome-nicasio).

* and on July 3, Jeff Sullivan opined ["The Mariners Are Trying to Be the Clutchiest Team on Record"](https://www.fangraphs.com/blogs/the-mariners-are-trying-to-be-the-clutchiest-team-on-record/)

Of course, regression to the mean is a thing, and later in the season their luck started to run out. 

---

I've written before about run scoring and prevention (index [here](http://bayesball.blogspot.com/search/label/run%20scoring)); this time, I will compare the individual team performance in a single season.  This will look at the simplest of the measures of "win expectation" that have burbled up in the Sabremetric community over the years; the other approaches may be worthy of consideration for a future post.


> For the 2018 season, our data source is [Fangraphs' team dashboard](https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season=2018&month=0&season1=2018&ind=0&team=0,ts&rost=&age=&filter=&players=0). It takes a bit of flinagalling to get what we want.

We'll rely on the [CRAN](https://cran.r-project.org/) version of the [`Lahman` package](https://cran.r-project.org/web/packages/Lahman/), which will (at this writing) take us through the 2016 season.


## Pythagorean win ratio


Bill James, the godfather of Sabermetrics, developed the Pythagorean win expectation model ([wikipedia page](https://en.wikipedia.org/wiki/Pythagorean_expectation)). The basic idea is that there is a relationship between the runs a team scores ($RS$) and allows ($RA$), and the proportion of the games that they can be expected to win ($WE$). The equation is expressed thus:

$$ WE = RS^2 / (RS^2 + RA^2)$$



### function

Let's write a one-line function for this equation. 

```{r}

winexp_fun <- function(RS, RA) {
  RS^2 / (RS^2 + RA^2)
}

```


## Empirical test

For this, we'll use the Major League Baseball data from 1961 through 2016--a total of 1476 team seasons.

This code chunk accesses the `Teams` table from the Lahman database, and wrangles it a bit, and adds (though the `dplyr::mutate` function) two new variables: the team's winning percentage, and using the `winexp_fun` function above, the win expectancy.

```{r}

data(Teams)

Teams_sel <- Teams %>%
  filter(yearID >= 1961) %>%
  rename(RS = R) %>%
  mutate(winpct = W / G, 
         winexp = winexp_fun(RS, RA))


```


#### plot

Use ggplot2 to look at the relationship between the Pythagorean estimate and the true value. We can do this in a couple of ways: one is to overlay the density plots of the two variables, and the other is an X-Y scatterplot.

> need to add a legend. See http://www.rpubs.com/dvdunne/adding_legend, https://stackoverflow.com/questions/29563375/plotting-line-legend-for-two-density-curves-with-ggplot2

```{r}

ggplot(data = Teams_sel) +
  geom_density(aes(x = winexp), colour = "red") +
  geom_density(aes(x = winpct), colour = "blue")
                 

ggplot(data = Teams_sel) +
  geom_density(aes(x = winexp, colour = "winexp"), show.legend = FALSE) +
  stat_density(aes(x = winpct, colour = "winpct"),
               geom = "line", position = "identity", size = 0) +
  guides(colour = guide_legend(override.aes=list(size=1)))

  

ggplot(data = Teams_sel, aes(x = winexp, y = winpct)) +
  geom_point()




```


#### The regression model

```{r}

winexp_mod <- lm(winexp ~ winpct, Teams_sel)

print(winexp_mod)

summary(winexp_mod)

```



Add the model line to the scatter plot

```{r}

ggplot(data = Teams_sel, aes(x = winexp, y = winpct)) +
  geom_point() +
  geom_smooth(method = lm) +
  coord_fixed() +
  xlim(.2, .8) +
  ylim(.2, .8)




```



_interpretation_



Use `broom` to get the model statistics

David Robinson, 2015-03-19, ["broom: a package for tidying statistical models into data frames"](https://www.r-bloggers.com/broom-a-package-for-tidying-statistical-models-into-data-frames/)

* also https://cran.r-project.org/web/packages/broom/vignettes/broom.html 



```{r}

tidy(winexp_mod)

```


```{r}

glance(winexp_mod)

```

```{r}

winexp_mod_tidy <- augment(winexp_mod)
head(winexp_mod_tidy)

```



The Pythagorean model explains a lot of the variation: the R-squared value of `r glance(winexp_mod)$r.squared`



One of the interesting things we can look at is the difference between the Pythagorean predicted value (`winexp`) and the actual value (`winpct`).



In this plot, the cases above the red line are where teams have outperformed their win expectancy, and those below the line have failed to win as many games as the Pythagorean model would predict.

What we are really interested in are the extreme cases--some of those single dots that are visible outside the main cloud that is clustered around the line.


```{r}


ggplot(Teams_sel, aes(x = winexp, y = winpct)) +
  geom_point() +
  geom_segment(aes(x = 0.3, xend = 0.7, y = 0.3, yend = 0.7), colour = "red", size = 1)


```



And just for fun, let's compare the "unity" line shown in red (where `winexp` == `winpct`) and the line of best fit created by the regression model (in blue). There's a slight discrepancy (figure out what it means--is it that teams at the bottom left are over-performing Pythagorean, suggesting winning more close games, while those at the top are underperforming, meaning they are winning more blowouts?)


```{r}

ggplot(Teams_sel, aes(x = winexp, y = winpct)) +
  geom_point() +
  geom_segment(aes(x = 0.3, xend = 0.7, y = 0.3, yend = 0.7), colour = "red", size = 1) +
  geom_smooth(method = lm)

```



### Further reading

FanGraphs ["BaseRuns" page](https://www.fangraphs.com/depthcharts.aspx?position=BaseRuns)

* [Pythagorean Win-Loss](https://www.fangraphs.com/library/principles/expected-wins-and-losses/)

* [Pythagorean Win-Loss](https://www.fangraphs.com/library/team-record-pythagorean-record-and-base-runs/)

* See also ["BaseRuns" definition](https://www.fangraphs.com/library/features/baseruns/) for alternative measure

Jay Heumann, ["An improvement to the baseball statistic 'Pythagorean Wins'"](https://content.iospress.com/download/journal-of-sports-analytics/jsa0018?id=journal-of-sports-analytics%2Fjsa0018), _Journal of Sports Analytics_ 2 (2016) 49–59


---


## ETC - future analysis possibilities

Idea: filter where .se.fit is poor (i.e. big residual), plot -- see where the 2018 Mariners sit on the list


Idea: regression to the mean over the course of a season, via a Bayesian MCMC approach 



---



#### `ggplot2 3.0.0`

This also seemed like a good time to take [the latest version of `ggplot2` (3.0.0)](https://www.tidyverse.org/articles/2018/07/ggplot2-3-0-0/) for a test run.



#### `ggeffects` package

Daniel Lüdecke, 2018-07-04, ["Marginal Effects for Regression Models in R"](https://www.r-bloggers.com/marginal-effects-for-regression-models-in-r-rstats-dataviz/)



