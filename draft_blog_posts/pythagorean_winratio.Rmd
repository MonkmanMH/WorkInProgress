---
title: "Regression models and win expectancy"
output: html_document
---


Mid-way through the 2018 Major League Baseball (MLB) season, the Seattle Mariners were sitting in second place in the American League West, with a winning percentage over .600. 

The Mariners' relatively small run differential (i.e. how many more runs they scored than allowed) had been noted all season; 

* at the end of the first month of the season Jake Mailhot (@jakemailhot) at Lookout Landing wrote ["Just how lucky have the Mariners been?"](https://www.lookoutlanding.com/2018/5/1/17308386/mariners-cluster-luck-april-run-differential); 

* on May 25, Sports Illustrated carried an article ["The Mariners Have Been Very Lucky, But They May Also Be Pretty Good"](https://www.si.com/mlb/2018/05/25/seattle-mariners-al-west)

*at the end of May (2018-05-29) John Trupin (@JohnTrupin) on the same site wrote ["The Mariners aren’t the first team built on a run differential-beating bullpen"](https://www.lookoutlanding.com/2018/5/29/17406204/the-mariners-arent-the-first-team-built-on-a-run-differential-beating-bullpen-diaz-colome-nicasio).

* and on July 3, Jeff Sullivan opined ["The Mariners Are Trying to Be the Clutchiest Team on Record"](https://www.fangraphs.com/blogs/the-mariners-are-trying-to-be-the-clutchiest-team-on-record/)

Of course, [regression toward the mean](https://en.wikipedia.org/wiki/Regression_toward_the_mean) is a thing, and later in the season their luck started to run out. 


---

I've written before about run scoring and prevention (index [here](http://bayesball.blogspot.com/search/label/run%20scoring)); this time, I will examine the individual team performance in a single season, looking at the simplest of the measures of "win expectation" that have burbled up in the sabermetric community over the years; the other approaches may be worthy of consideration for a future post.

## Pythagorean win ratio


Bill James, the godfather of Sabermetrics, developed the Pythagorean win expectation model ([wikipedia page](https://en.wikipedia.org/wiki/Pythagorean_expectation)). The basic idea is that there is a relationship between the runs a team scores ($RS$) and allows ($RA$), and the proportion of the games that they can be expected to win ($WE$). The equation is expressed thus:

$$ WE = RS^2 / (RS^2 + RA^2)$$



### function

Let's write a one-line function for this equation. 

```{r}

winexp_fun <- function(RS, RA) {
  RS^2 / (RS^2 + RA^2)
}

```


## Empirical test


First, we'll load the packages we need. Note that `tidyverse` contains multiple packages, including the graphing package `ggplot2` and the data wrangling package `dplyr`. We'll also load `broom`, which facilitates manipulation of the regression model outputs.

For this analysis, we'll use the Major League Baseball data from 1961 through 2016--a total of 1476 team seasons. To get the data, we'll rely on the [CRAN](https://cran.r-project.org/) version of the [`Lahman` package](https://cran.r-project.org/web/packages/Lahman/), which will (at this writing) take us through the 2016 season. 




```{r setup}

library(tidyverse)
library(broom)

library(Lahman)

```


The code chunk below accesses the `Teams` table from the Lahman database, and wrangles it a bit, and adds (though the `dplyr::mutate` function) two new variables: the team's winning percentage, and using the `winexp_fun` function we wrote above, the win expectancy.

```{r}

data(Teams)

Teams_sel <- Teams %>%
  filter(yearID >= 1961) %>%
  rename(RS = R) %>%
  mutate(winpct = W / G, 
         winexp = winexp_fun(RS, RA))


```


#### plot

Use ggplot2 to look at the relationship between the Pythagorean estimate and the true value. We can do this in a couple of ways: one is to overlay the density plots of the two variables, and the other is an X-Y scatterplot.

First the density plot.

```{r}

ggplot(data = Teams_sel) +
  geom_density(aes(x = winexp, colour = "winexp"), show.legend = FALSE) +
  stat_density(aes(x = winpct, colour = "winpct"),
               geom = "line", position = "identity", size = 0) +
  guides(colour = guide_legend(override.aes=list(size=1)))

# tips from https://stackoverflow.com/questions/29563375/plotting-line-legend-for-two-density-curves-with-ggplot2


```


Next, the scatter plot. Because we are going to return to the foundations of this plot (i.e. the calculated win expectancy as the X axis and the end-of-season final winning percentage plotted on the Y axis), we'll create a blank frame in an object called `we_scatterplot`. 

Note that there's a few things going on here:

* the use of the `geom_blank` function; usually, we would call `geom_point` for a scatter plot. 

* the `coord_fixed` means that the X and Y scales have the units represented by equal length on both (one tenth of a point is the same length on each). 

* the `scale_x_continuous` function and its parallel for y set the grid marks and length of the two axes.


```{r}

we_scatterplot <- ggplot(data = Teams_sel, aes(x = winexp, y = winpct)) +
  geom_blank() +
  coord_fixed() +
  scale_x_continuous(breaks = seq(0.2, 0.8, by = 0.1),
                     limits = c(0.2, 0.75)) +
  scale_y_continuous(breaks = seq(0.2, 0.8, by = 0.1),
                     limits = c(0.2, 0.75)) 

we_scatterplot

```


The `we_scatterplot` object contains the `winexp` and `winpct` data points, so we can summon them in the `geom_` that we want. 

Now, we'll render that object but using the `geom_point` so we can see the winexp and winpct values.

```{r}


we_scatterplot +
  geom_point()



```


#### The regression model

```{r}

winexp_mod <- lm(winexp ~ winpct, Teams_sel)

print(winexp_mod)

summary(winexp_mod)

```



Add the model line to the scatter plot

```{r}

we_scatterplot +
  geom_point() +
  geom_smooth(method = lm) +
  coord_fixed() +
  xlim(.2, .8) +
  ylim(.2, .8)




```



_interpretation_



Use `broom` to get the model statistics

David Robinson, 2015-03-19, ["broom: a package for tidying statistical models into data frames"](https://www.r-bloggers.com/broom-a-package-for-tidying-statistical-models-into-data-frames/)

* also https://cran.r-project.org/web/packages/broom/vignettes/broom.html 



```{r}

tidy(winexp_mod)

```


```{r}

glance(winexp_mod)

```

```{r}

winexp_mod_tidy <- augment(winexp_mod)
head(winexp_mod_tidy)

```



The Pythagorean model explains a lot of the variation: the R-squared value of `r glance(winexp_mod)$r.squared`



One of the interesting things we can look at is the difference between the Pythagorean predicted value (`winexp`) and the actual value (`winpct`).



In this plot, the cases above the red line are where teams have outperformed their win expectancy, and those below the line have failed to win as many games as the Pythagorean model would predict.

What we are really interested in are the extreme cases--some of those single dots that are visible outside the main cloud that is clustered around the line.


```{r}


we_scatterplot +
  geom_point() +
  geom_segment(aes(x = 0.3, xend = 0.7, y = 0.3, yend = 0.7), colour = "red", size = 1)


```



And just for fun, let's compare the "unity" line shown in red (where `winexp` == `winpct`) and the line of best fit created by the regression model (in blue). There's a slight discrepancy (figure out what it means--is it that teams at the bottom left are over-performing Pythagorean, suggesting winning more close games, while those at the top are underperforming, meaning they are winning more blowouts?)


```{r}

we_scatterplot +
  geom_point() +
  geom_segment(aes(x = 0.3, xend = 0.7, y = 0.3, yend = 0.7), colour = "red", size = 1) +
  geom_smooth(method = lm)

```



### Further reading

FanGraphs ["BaseRuns" page](https://www.fangraphs.com/depthcharts.aspx?position=BaseRuns)

* [Pythagorean Win-Loss](https://www.fangraphs.com/library/principles/expected-wins-and-losses/)

* [Pythagorean Win-Loss](https://www.fangraphs.com/library/team-record-pythagorean-record-and-base-runs/)

* See also ["BaseRuns" definition](https://www.fangraphs.com/library/features/baseruns/) for alternative measure

Jay Heumann, ["An improvement to the baseball statistic 'Pythagorean Wins'"](https://content.iospress.com/download/journal-of-sports-analytics/jsa0018?id=journal-of-sports-analytics%2Fjsa0018), _Journal of Sports Analytics_ 2 (2016) 49–59


---


## ETC - future analysis possibilities

Idea: filter where .se.fit is poor (i.e. big residual), plot -- see where the 2018 Mariners sit on the list


Idea: regression to the mean over the course of a season, via a Bayesian MCMC approach 



---



#### `ggplot2 3.0.0`

This also seemed like a good time to take [the latest version of `ggplot2` (3.0.0)](https://www.tidyverse.org/articles/2018/07/ggplot2-3-0-0/) for a test run.



#### `ggeffects` package

Daniel Lüdecke, 2018-07-04, ["Marginal Effects for Regression Models in R"](https://www.r-bloggers.com/marginal-effects-for-regression-models-in-r-rstats-dataviz/)



